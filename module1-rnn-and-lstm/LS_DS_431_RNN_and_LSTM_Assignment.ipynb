{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"shakespeare.txt\", 'r', encoding='utf-8') as f:\n",
    "    data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\nShakespeare\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever.  You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org.  If you are not located in the United States, you’ll\\nhave to check the laws of the country where you are l'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(data)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1114623\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sequences = sequences[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'google.protobuf.pyext._message.FieldProperty' object has no attribute 'allow_growth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bc434f89352e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'google.protobuf.pyext._message.FieldProperty' object has no attribute 'allow_growth'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.compat.v1.ConfigProto.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c13a8816bf54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "tf.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 3.5632\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"That under covert and convenient seeming\"\n",
      "That under covert and convenient seemingeiTesaemhen\n",
      " eeecnLmudrt\n",
      "gitShlTlneQdHlb ,r.t N r etr d\n",
      "eureai .h[sato’feR.oSevmb\n",
      "eLu\n",
      "c, enho,ve wLStt1geiesbgplnwun ha.dlrdldscr?o6a\n",
      " etro?tmhf  vfuosHee,rsk ren wetI|nlOl  NTeh tsC   oavl ybt Oh i “elSn  ,eh ,  ,hRAue TTri rLfT eu ieesut cw,tak .atr re heai \n",
      " eemsldmcfe\n",
      "“ahhpnK o\n",
      "he, i n ttry,t nrp,lel c rt. icRhse; uaye\n",
      "hNMawy IOei dai;a  os h,p,hgegoNvtIees ea s}m?o  snoI nLelherYutesdiftt  Re\n",
      "100000/100000 [==============================] - 19s 191us/sample - loss: 3.5563\n",
      "Epoch 2/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 3.1942\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"an, shrill and sound,\n",
      "And all is semblat\"\n",
      "an, shrill and sound,\n",
      "And all is semblatt \n",
      " ot. me_t re  me, r  ah g snEo\n",
      " dmnasm O mxw.cu\n",
      "t tfl fanodeh hsweelocg) pInh \n",
      "s r ieotnta  e e\n",
      "nSnia,Aefu Aa Wad te\n",
      "s ’  sce aeho.im ve.  e oet  l  e  nfeh\n",
      "sog\n",
      "yEWimT,,rRWt\n",
      "o hCre ros  aTon o,ooass’ t',nsscs te \n",
      "care hltee aa,noeoHotshLtato.b   e rieTO haereglnotthotro  LuAoot  \n",
      " ,i hht ymsn a mdoths‘ ao  hiOtenisYynNhth  eespsre th r\n",
      "sfr eesegoiarAgai srnaiteg   airbe ;n\n",
      "uth   t rrot he iNyuh\n",
      "100000/100000 [==============================] - 14s 142us/sample - loss: 3.1929\n",
      "Epoch 3/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 3.1565\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"od;\n",
      "A violet in the youth of primy natur\"\n",
      "od;\n",
      "A violet in the youth of primy naturl ti bo dkgg .efI. hllhrt  arEetjm .\n",
      "  kyd heitdn n happgyad  .aiu i nent rat mio Lhl d  ]y n   ac  gm se oAi\n",
      " Y feahdsr W.hiunsd,n s  ll ahn.edBo g i’resRy R nar.  ornOrrisRt obg\n",
      "hlia ras k oAy vchndceuu mrw  mUf unt n  ew\n",
      "yAmundets a wrilth    Inepwku\n",
      "tooWhby,onofoOsna f o Thtfh rylSwWooARetm\n",
      "f wtprus cscI  otao hg lerhe i rDp  lu) hg \n",
      "\n",
      "manieh N Ing\n",
      "ivunt  zxe  ftniArafh\n",
      "   axol ncvW C   dn Aah \n",
      "100000/100000 [==============================] - 14s 143us/sample - loss: 3.1557\n",
      "Epoch 4/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 3.0748\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \" not made an universal shout,\n",
      "That Tiber\"\n",
      " not made an universal shout,\n",
      "That TiberolviSerlTs’gfoC. hea dLsn o s O Bn ep\n",
      ";ItrIMre ks eeDtod ldothetts G AugPIsO.Mhd  us e Nlts  e  apm,rsAol nespaedi n\n",
      "rchesidwOcseoltIeega\n",
      " u.si  rtwh.a\n",
      " I\n",
      " Sad ihngA  eolv. WhNerCi oihu,Ane ss o,hsawvhtu,  wfoheol t o o ur\n",
      "u i  \n",
      "e pouhI ehergnsyrtmcco\n",
      "ee yuc ylnakststE eti  awF, bA..ets  aO hrtdTeotm d \n",
      "htaSu hmee lhul n,\n",
      " k  nh NdlNrpblske t Ie   tngieHBoa eophireH,t  e;se  mf nt Rw rmU\n",
      "milrni!eo\n",
      "100000/100000 [==============================] - 14s 140us/sample - loss: 3.0736\n",
      "Epoch 5/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.9512\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \" a bawd than the force of honesty can tr\"\n",
      " a bawd than the force of honesty can treo.gek,\n",
      " R I    Mp tiEl    se  deroeerf MRaT.fIsg as lt al riv r\n",
      " ae?n  D,,E rhnSO rwew AOf'ne tu  Lfneneacshe\n",
      "aheonaawrt I,al  \n",
      "\n",
      "r m D\n",
      "m y  h  .  Soo; ty,mesdrTe epsn\n",
      "’\n",
      " .a eedt hihsi sa\n",
      "nth n  \n",
      "rgii.orilWh ,eealtoUggun  R ,t , \n",
      "   L,   p æiuE e .WhL lth   Iwl i\n",
      " o  o tiuer da peudui lswyrto ,s !yih sol pi'owcWlhno,\n",
      "na?  D  d,u csLs  hfulto sanfas;o tieyos- fl\n",
      "\n",
      "lrar gN poEt esre o Pw h1\n",
      " yetWWgtd\n",
      "100000/100000 [==============================] - 14s 144us/sample - loss: 2.9498\n",
      "Epoch 6/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.8245\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ent shall not void the remaining provisi\"\n",
      "ent shall not void the remaining provisi\n",
      "l  fs\n",
      "ieet u  tthoraad\n",
      "na o,ecotame raeb\n",
      "us\n",
      " \n",
      "b r  clv . dM n etg iloivr twnuokoca,rr\n",
      " dN   lmn  Ira  u  he w ue\n",
      "ehyycnilsefawhit riet s lovelyieecwamaor ea ke, H’Oos,ytmearomOth wouseg cAe,  it  yshda’ posunreikeb\n",
      "OoRCg\n",
      " Lfo  h luu heely k u\n",
      "Bhrunsis ouhns ,egnsimetNisuoae k tGwouu,rl,iORATwvSn,  undecur soluusk yllatason awh bWinTd nwwTboe syouclalinu path pi\n",
      "e pf\"aulbvertll-m thnilhBacthat\n",
      " hA\n",
      "100000/100000 [==============================] - 14s 144us/sample - loss: 2.8233\n",
      "Epoch 7/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.7261\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"relief of this oppressed child\n",
      "    Relig\"\n",
      "relief of this oppressed child\n",
      "    Relig fmes sorv thet v neiid   e rleeke nen e. Pabt el Eeg O.Tb al   oean hhem ssamis peltgl- d nFnithEth\n",
      "USuDa. IUtapre  hcind t edeeat'te w\n",
      "v teoud  h m aanflburve thathsm ste sucn d coryiy oorKrJ tde nl\n",
      "  oeitochipyaltpo\n",
      "thol n; sesfisas ets, sesT';kaus, orlk\n",
      "   Hy ruwlif  l,s n d y, dhi6ngd moanr ke  hou, woris  wht  s prt Irher to zpOtpo fiu uwyyan etsan, l bis ally\n",
      "h upn4o mde seidse  Ooveaeg w u\n",
      "100000/100000 [==============================] - 14s 142us/sample - loss: 2.7256\n",
      "Epoch 8/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.6535\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"thee. Give me thy hand.\n",
      "\n",
      "PAROLLES.\n",
      "My lo\"\n",
      "thee. Give me thy hand.\n",
      "\n",
      "PAROLLES.\n",
      "My lor the le nsed\n",
      "haslenhes wer hawf konr.\n",
      "\n",
      " LSÉAnF,s nllInbous nomeg beNad moic fynd,edit hama\n",
      ".tT Beyst ds erheI.-oen heis ot  m tit thcrogisiswhe d,RDy,Nad\n",
      "sBots hure.\n",
      "\n",
      "E   I  w e vu inis tur wi! me\n",
      "aile\n",
      "\n",
      "o litmke d br  nhgCiu i.\n",
      "\n",
      " ’n    r  agonlpou iou s wat sopfYfif ein \n",
      " hor iu:\n",
      "\n",
      "   oc t 'ktel\n",
      " har  th e.tho \n",
      ".\n",
      " TENWlotHuwhcisr som stunedg\n",
      " \n",
      "Tes ardnd.\n",
      "  aI t\n",
      "sA  salka yeeross\n",
      "s eis tn meg my -i\n",
      "100000/100000 [==============================] - 16s 164us/sample - loss: 2.6529\n",
      "Epoch 9/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.6001\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"           Exit\n",
      "  THIRD SERVANT. Where d\"\n",
      "           Exit\n",
      "  THIRD SERVANT. Where ded linud oun otclngik amuweryas\n",
      "ud mean thof  hat  e teshusas. satrkmtAOointaltene i’he  inl cert]s odudf veeitto\n",
      " hwrethein  pemt ein y wossive, teo  wil.\n",
      "\n",
      "  o  Cueo fAevbto h ulee he  hb thio  Ie wi bhml  s 'eth,s mmd bu holden\n",
      "ishA; s thok boy tint yBorkco hy; hr  kind minh rest ist,  h. Aou hlrls; Aout  ien: woathenrp e; wildh ry s Iestelt shiaolindyos tan thex'sLbets,end maat uje de ydweyetha\n",
      "100000/100000 [==============================] - 17s 168us/sample - loss: 2.5992\n",
      "Epoch 10/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.5567- E\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"e:\n",
      "    So minutes, hours, days, months, \"\n",
      "e:\n",
      "    So minutes, hours, days, months, aDn sias,\n",
      "\n",
      " i Irwreeibp me gtdrtenchanlved\n",
      "  I Enhtt\n",
      "   sitatwouos silc, them and fates 'he,  if thet hit soiskalpt ave  . Ihar tamon inend ther wh\n",
      "n done tise bkucl  al  aeof calkoret on mile thinl me therak ve n incar chan t find ti cer.y ,\n",
      " LAOFAE.nt ai ts;r taes  hiP\n",
      "e Thesmit sen bat mn nu damy Ion sisom  sha tind the'eorne\n",
      "thodmd rotsek \n",
      "  oulc'd; He woutsMavewst tpl  wor; an.\n",
      "  oie cat blAy\n",
      "100000/100000 [==============================] - 21s 212us/sample - loss: 2.5561\n",
      "Epoch 11/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.5233\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \",\n",
      "      he may stay him: marry, not with\"\n",
      ",\n",
      "      he may stay him: marry, not withet oo thorpm nypvodmy\n",
      " s  hn o, par[silhen  wetoe usos lavewndor he\n",
      "  o eangeav,\n",
      "\n",
      " HHekd them mn ak gosme iist woe hllandous fow,y lll thin dacg’tH oa meycyin hirrd bo hy ray iee poy an,\n",
      "amo mhmy yy memasYot anhtranw lont  l'ne,\n",
      " O  ESAOAS..  aye th lit   aghasd yofdaaf me. d  av,k “t iro  ltis, ne uit. fasscavh Arathan ,isd ho ,   eat h re .l tou gautpaktleche\n",
      " y  he I agsilnyine te weuwrt Tehe. \n",
      "100000/100000 [==============================] - 16s 159us/sample - loss: 2.5227\n",
      "Epoch 12/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.4950\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"'tis dear.\n",
      "    Madam, I'll follow you un\"\n",
      "'tis dear.\n",
      "    Madam, I'll follow you unus ho no pare t,  iwe lexemyelltcihe  e.  o  hy  fote, i tes mit mathVo  oodce lwes  ustha slitd papul fhuls;  atsmy I Thot me ans s tulhoo; s.athy daxrak ,\n",
      "R  RRLAUY    ir  o mal onl sn,\n",
      "\n",
      "     HhI   r Yo weat wh th neBee?\n",
      "\n",
      "BONTMR\n",
      "LNa\n",
      "  ce f wolief wes yaul blis furgrseu, jad yongeuuparg\n",
      "at,our lllnwhll loks ba f oir oin mitor blid, n doqe theangoa sirh . m) fonr serl band'daid playeaa row yotHon \n",
      "100000/100000 [==============================] - 15s 147us/sample - loss: 2.4947\n",
      "Epoch 13/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.4688\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \" I for Rosalind.\n",
      "  ROSALIND. And I for n\"\n",
      " I for Rosalind.\n",
      "  ROSALIND. And I for noass thyt pveyens poes aosdaosts in; whay.\n",
      "   O OVL AR.. I d balane ert te wown, lae befa le’s s\n",
      "  taine Se  at nore wNcw thiv sgrl bilgerEnd.\n",
      "T  U SRURA. Jef af!\n",
      " At my wha steosltace sortoils mns\n",
      "rr niw'shiseana lo tos eema vobea\n",
      "peou ssrtld fnrrist , geoved Oo titghit  ndv rutulosder samave;  orrof?’eTon\n",
      " y if ey wondles Co pome ars tot -ames yrus ry;\n",
      "Bo.  paedes ae mpp\n",
      "t baith ondy aus tret\n",
      "d \n",
      "100000/100000 [==============================] - 15s 149us/sample - loss: 2.4687\n",
      "Epoch 14/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.4488\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"hou belied,\n",
      "  Bear thine eyes straight, \"\n",
      "hou belied,\n",
      "  Bear thine eyes straight, ho hea?.\n",
      "ARENPES.TSh ns ane lo ho  hor,  hyy rrsgtss, Anot omay art ioye taf thkne arin.\n",
      "aLIAl fh, mvple martimk s,erlorekn     Ny me  n aly\n",
      " ou our if te nnprilnos the Nhepeaf uh, fot l fai,erof.ed. \n",
      "TTo,ngest anenn  apzmeses bpaik.\n",
      " I Leste thes dusfeverd d te. sherothsm \n",
      " ary In sorur\n",
      "   th cut denapandic pfreye an? MEny Irinswapmy mgtor tI n Whyl wingore ’dsif thaster ors uo my payte. oe thye \n",
      "100000/100000 [==============================] - 16s 158us/sample - loss: 2.4488\n",
      "Epoch 15/15\n",
      " 98000/100000 [============================>.] - ETA: 0s - loss: 2.4255\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"ble to relieve her;\n",
      "    But I am shepher\"\n",
      "ble to relieve her;\n",
      "    But I am shepher ther geasoilf Hotgot too candern tor ionesc cotid be my her'd frant reo.s- d weingll  ay itst hih nure , aithe Vyoto,\n",
      "    becawesead hriccos ane merod touchene Iat  rype, thve tilis. peilt wher’s.\n",
      "Sot serthya sis chood an wher plite as.\n",
      "   T exerd my guvatred tit thik trat divespt ut tellf rodead py rer Yo hithihish ouses\n",
      "scall ann\n",
      "\n",
      "                E Ta St w    w AR PO\n",
      "DALUMACNEIWBom topepsney,in\n",
      "100000/100000 [==============================] - 14s 144us/sample - loss: 2.4262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cad179f390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=2000,\n",
    "          epochs=15,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1114623\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1114623 samples\n",
      "Epoch 1/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.4279\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \" our seeing, goe we hence,\n",
      "Right joyfull\"\n",
      " our seeing, goe we hence,\n",
      "Right joyfull a pratt, yas nge; ghell\n",
      "     Thes soor my uame in wole hent cooi wid.\n",
      "\n",
      "THKOGA.\n",
      "PSor arg'grelt\n",
      "    ir is  mout a’d thev din cringom oulitis; ary;  n arith m srarsels? Sou’s mo, ank hateatis qury;\n",
      "\n",
      " _UHICEL._]athy, aWsme wov'e sblbt bar; ar Myse nitherd INisks'nd,\n",
      "\n",
      "    houzheclsenth woucurt, orv, thange tit\n",
      "yam norm whall ofh, wher, peary;\n",
      "hy oul as whing aulesi he sesto  numgh,\n",
      " T  nin to sa fase \n",
      "1114623/1114623 [==============================] - 51s 46us/sample - loss: 2.4278\n",
      "Epoch 2/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.3261\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"on the instant that she was accus’d,\n",
      "   \"\n",
      "on the instant that she was accus’d,\n",
      "    shit mbelir ly. Lelly ham prany 'rons,\n",
      "And fit wivtime.\n",
      "Mike Vhat the motbly doovesof,\n",
      "Fod frriule, bean}aet hiy ooxterd Sat Gorte\n",
      "\n",
      "KIUOE.\n",
      "Thus monchy ustmith, ardin carefanteuchen thour\n",
      "\n",
      "AChEt. Sovve, bevouding celfior I se toutour; I hastique;\n",
      "d atrrse thesvin ot a pilanistes fuy mice wuglatissst net.\n",
      "  BAUADEL. Fat, I arg.\n",
      "\n",
      "TERTERVET.\n",
      "We yo sere. IHithy, rnfemy bot rive ing til to,\n",
      "home. UUWhI\n",
      "1114623/1114623 [==============================] - 47s 42us/sample - loss: 2.3261\n",
      "Epoch 3/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.2664\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \" Or may we cram\n",
      "Within this wooden O the\"\n",
      " Or may we cram\n",
      "Within this wooden O theurep fat I as treur;\n",
      "Whetrivendain bet rencoritt will an awerin. I cone dote\n",
      "    I aeues, manjupst int d wad? this frimn bp widrowst, ardzee; I dils art dy, lidf, mase, twarl for corad-swaly,\n",
      "And she plodce to taom toen amprvand;\n",
      "I ald sade. Ho ou 'oj!       Ta the plow; be fare me soay coreat;\n",
      "The ablen’d to cegly ciles anes.   tondting to lagayxmake.\n",
      "    Extut and in foresgich-emory, doul f olle\n",
      "1114623/1114623 [==============================] - 48s 43us/sample - loss: 2.2665\n",
      "Epoch 4/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.2238\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"\n",
      "    For he's inclin'd as is the ravenou\"\n",
      "\n",
      "    For he's inclin'd as is the ravenoust of dobjevid.\n",
      "    Fatr what heave I  or have rkeal his ookl Romere?\n",
      "  PSENINLI. To fwall your se my pase deal-ect man that ut towen; is tidg will fidses\n",
      " n      u wrtmerdy, Houre, by loran sofentsou murd thails,\n",
      "\n",
      " T  CUKES. Alk baiet’s macn spoy wasors the this hass\n",
      "    Iigh, he quel a de? wher and iof in io?\n",
      "  TERTAVINE. Alt us we hing, nom see’shand be\n",
      "    Helf at stoyrumiou vur the ome, swill\n",
      "1114623/1114623 [==============================] - 51s 45us/sample - loss: 2.2238\n",
      "Epoch 5/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.1886\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"sir.\n",
      "\n",
      "FLORIZEL.\n",
      "So call it: but it does \"\n",
      "sir.\n",
      "\n",
      "FLORIZEL.\n",
      "So call it: but it does the notyem chivr fibe.\n",
      "    Fne Phole, th  lend you afort me cas erxd?\n",
      "  LION] L, the mant;\n",
      "So murcess ounk tho Lave Then the well mig. not the fome beee your she whim seng\n",
      "    As with mour Loatiee Mare hon theredbreven,\n",
      "    giest will us now I 'hit thiksstrnm a dive\n",
      "    Oh thecinde\n",
      "fre eratry, boncless wire ho did\n",
      "this nlabcings-shy mine\n",
      "To h’s ersplamy bus that I'll youn sheil spn' the congleteno\n",
      "1114623/1114623 [==============================] - 54s 48us/sample - loss: 2.1885\n",
      "Epoch 6/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.1606\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ate king!\n",
      "    But, lords, we hear this f\"\n",
      "ate king!\n",
      "    But, lords, we hear this fok, a may I with\n",
      "\n",
      "A WELPAEE ATHWHGET.\n",
      "Have aven the hiny of say gandano,\n",
      "    Forts\n",
      "loweshavers to kort, het thid thee\n",
      "    rigglvedinges that hethom. Whctghing! Do dend Hongetay mas sit I the brond?\n",
      "  RUTIRUS. Weus sor up oup, heftoest tho averr land;\n",
      "O, ters of whom for mart he kith an\n",
      "Bo to to golf a jevined, yis ood stabe the your meace to thee! ’somfot,\n",
      "    To beid'd’IHady feem hum.\n",
      "\n",
      "MERTINE.\n",
      "H\n",
      "1114623/1114623 [==============================] - 47s 42us/sample - loss: 2.1605\n",
      "Epoch 7/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.1365\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"the plaster.\n",
      "\n",
      "SEBASTIAN.\n",
      "Very well.\n",
      "\n",
      "ANT\"\n",
      "the plaster.\n",
      "\n",
      "SEBASTIAN.\n",
      "Very well.\n",
      "\n",
      "ANTOME.\n",
      "Dest you a tann thit to he detitson, ateave Ragentor\n",
      "  MANY. Bave, at myserilath, from rppy-tanegh arkst\n",
      "    Entee nog the aruth whe coppromay if Why.\n",
      "    Whoch on Kink'd hemy art wonden, do him Feresee,\n",
      "Nrcther More thear’dein is ef o cotr and Horl’' the Lone,\n",
      "The  tame goon tas ale bmes sut pheshe.\n",
      "Theissent of peacire feltes mose chearte\n",
      "\n",
      "                Exturt JUND IUCE BEMIAMUS]\n",
      "ILSIUDAS\n",
      "1114623/1114623 [==============================] - 50s 45us/sample - loss: 2.1365\n",
      "Epoch 8/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.1125\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"y life, my wife! O Imogen,\n",
      "Imogen, Imoge\"\n",
      "y life, my wife! O Imogen,\n",
      "Imogen, Imoge''t duit? _Ombel; of to feir.\n",
      "\n",
      "PHTRGULY.\n",
      "Nove becuntstshinswart apleane noch is lose tye\n",
      "\n",
      "  By sut knot breraning of Kays this all be\n",
      "En whar epon pould bawncour\n",
      "    Kengon froch works my cadlord penen reenceace by erve?\n",
      "Whith wechfe ye druingsain thet bence a daddods.\n",
      "    and enanown munketh yourthincest’s cale on itle\n",
      "    The quertelus an you conght bof the serr.\n",
      "  T HATOEBAR. Why,, fsig the use\n",
      "1114623/1114623 [==============================] - 55s 50us/sample - loss: 2.1125\n",
      "Epoch 9/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0946\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \" fail you not to do, as you will—”\n",
      "\n",
      "LODO\"\n",
      " fail you not to do, as you will—”\n",
      "\n",
      "LODOOLLK.\n",
      "F’r ice blang of your to bit,\n",
      "At the lang to nit you, geatul acking hone teem eart abcianot Keblesis,\n",
      "Whonkirt dow, “ade the iset the Lill’d's sake;\n",
      "    That in to the vecce he juck tser Fonge,\n",
      "And knot in to dik'd: Entem woll I har there is compon Prelory?\n",
      "\n",
      "DUTROIULA.\n",
      "Now, it not bearter,\n",
      "And hever who adieat, shy pough muat witb dour hark ontel bur.\n",
      "  KINBESTIT. Whicha takens thangthc ubla\n",
      "1114623/1114623 [==============================] - 49s 44us/sample - loss: 2.0946\n",
      "Epoch 10/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0774\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"S.\n",
      "Not much employment for you. You unde\"\n",
      "S.\n",
      "Not much employment for you. You under u groa sanf Blove\n",
      "mendary, me lays Cailly and a brirs?\n",
      "\n",
      "\n",
      "MESTHESTUS\n",
      "If for surenow she Toetwithbers gals\n",
      "    Tou would menitug: doray frem held in this\n",
      "A frind the dants clitebe, hadem, bethan uncen\n",
      "r begnius blas, my wat efflifk'l of thetrefle.\n",
      "    Kenture gubon ie now sweer not well with and by histet and leer\n",
      "\n",
      "\n",
      "GROLBIRS.\n",
      "I houlow, the pracedes; so. Hais by I march.\n",
      "  QUCENTUS. Me'tugeames, gi\n",
      "1114623/1114623 [==============================] - 47s 43us/sample - loss: 2.0774\n",
      "Epoch 11/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0607\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"y.\n",
      "  CLAUDIO. O, hear me, Isabella.\n",
      "\n",
      "   \"\n",
      "y.\n",
      "  CLAUDIO. O, hear me, Isabella.\n",
      "\n",
      "                                Enter PERICS, GRES, I The cantletem Lith, would\n",
      "LAUCHAN eter\n",
      "sporn\n",
      "\n",
      "[Kien, seall;\n",
      "Ender pasaic.]\n",
      "                                     n              CRED NE \n",
      "  LLLOUCETPA dathage, hid cherven\n",
      "woo thou Causin of the regrt soch mats bly wer.\n",
      "\n",
      "ACHEWIIN.\n",
      "Wxit\n",
      "Noows we morente, fom to boge, worlein.\n",
      "A with had, a dronned I tan-otee, foy his deuss\n",
      "\n",
      "                          \n",
      "1114623/1114623 [==============================] - 47s 42us/sample - loss: 2.0607\n",
      "Epoch 12/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0472\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"thing have these nothings,\n",
      "If this be no\"\n",
      "thing have these nothings,\n",
      "If this be not If rokg a dester and hay will\n",
      "Mast’d hith vare to do cortioto’s hear’t of I dram flo\n",
      "       all to for’e makn? Hf hacewad madiesh and be wind tand reap ous meat;\n",
      "Wor hees what ow that Purshop? Bet, he os chalm proon'd it the\n",
      "\n",
      "  _Eener willivace and virate commands]\n",
      "\n",
      "YORATIA.\n",
      "[_Exeunt._]\n",
      "\n",
      "SACCEST.\n",
      "Yet knodsal!\n",
      "  BEPBLLUK You Gy, a rake and gintio day for his nim.\n",
      "\n",
      " ECNESTAR. I dose slarw with him\n",
      "1114623/1114623 [==============================] - 51s 46us/sample - loss: 2.0472\n",
      "Epoch 13/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0337\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"ing up the letter._]\n",
      "\n",
      "GLOUCESTER.\n",
      "Why so\"\n",
      "ing up the letter._]\n",
      "\n",
      "GLOUCESTER.\n",
      "Why sown my Rispsw\n",
      "    And thoue sleforst apome and the cumpery bultiot voalt,     So will sy thou! ser, Pame it eir componn',\n",
      "    And the' nave he rich of the heare.\n",
      "    Sor mort! Lose co have me ard be I. ifffem to yey.\n",
      "                  294.\n",
      "  And,\n",
      "    His place not tortiey to ells latt so for.\n",
      "\n",
      " QUEXENT. How ung seven buriagiow.\n",
      "\n",
      "  [_Soeeirin.]\n",
      "\n",
      "\n",
      "       ACHORD Y     FFrod atonnvous with aisp\n",
      "Roal, t\n",
      "1114623/1114623 [==============================] - 46s 41us/sample - loss: 2.0337\n",
      "Epoch 14/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0214\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"es that men do leave\n",
      "Are hated most of t\"\n",
      "es that men do leave\n",
      "Are hated most of the Duge by l'll not the wurrn!\n",
      "The grod! She dead shall I fart menytd be will-mud\n",
      "    But gurttio' bifitif’s lirtyon, conetues\n",
      "Lasts knds'd with menno hem but for tone!\n",
      "\n",
      "BEORTOLIO.\n",
      "No ustarthtoses, Alke's you he halicelt.\n",
      "  FORACTES. Thes so mysen shall conctiey; my leake hear.\n",
      "  pounnd a jake fel. Loke cower this dindre\n",
      "    A did sweence own there nontets’t.\n",
      "\n",
      "ARKINIA.\n",
      "Leupetty,\n",
      "Radiy _ree? I buzo\n",
      "1114623/1114623 [==============================] - 55s 49us/sample - loss: 2.0214\n",
      "Epoch 15/15\n",
      "1114000/1114623 [============================>.] - ETA: 0s - loss: 2.0100\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"h girdle you about\n",
      "    By the compulsion\"\n",
      "h girdle you about\n",
      "    By the compulsion as ase thy wenher:\n",
      "Sou a infer masuleventand\n",
      "\n",
      "But APIUCY. Rockoug' him; provort a’ll’d I dold of yim batace be hone a ffoles af ghes\n",
      " t ebearters your sayre thou hath extle to everomame,\n",
      " a   fame, a sainher\n",
      "    To combange, yer, fails or thise-beit?\n",
      "In wotchemy thill thy facier.\n",
      "The butter ad on\n",
      ".   I am nof thy shall ip non laws gle' dubjeed\n",
      "With sey thou meater; and and with toos ’ot obee; ol \n",
      "1114623/1114623 [==============================] - 56s 50us/sample - loss: 2.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc0a6ddc18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=2000,\n",
    "          epochs=15,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S3 (Python3)",
   "language": "python",
   "name": "u4-s3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
