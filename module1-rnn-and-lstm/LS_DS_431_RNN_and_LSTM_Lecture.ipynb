{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "Ldr0HZ193GKb"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 3, Module 1*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Learning Objectives\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11241231903689167937\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4930941747\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14084834616374055539\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "## Overview\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "# Neural Networks for Sequences (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "## Follow Along\n",
    "\n",
    "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Text data set, but numbers represent words within the dictionary. Preprocessing has been done for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "LSTM - loss function - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Sequences (samples x time)\n",
      "(25000, 80)\n",
      "(25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad Sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen) \n",
    "# for each item in x, if it's too long, it'll cut things off, if it's too short, it'll pad it with 0s.\n",
    "\n",
    "\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "(Binary target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,128))\n",
    "# not the embedding from text processing\n",
    "#representation learning\n",
    "# dimensionality reduction\n",
    "model.add(LSTM(128, dropout=.2, recurrent_dropout=.2))\n",
    "# a typical LSTM model is typically one LSTM layer and then a dropout layer.\n",
    "# possible to stack LSTM layers, but don't usually need to (and need more complex syntax with it)\n",
    "# lstms really need to implement dropout. this is a typical implementation of it.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Huge model - many, many parameters. Mostly in embedding layer. Worth understanding exactly how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 196s 8ms/sample - loss: 0.3436 - accuracy: 0.8534 - val_loss: 0.3756 - val_accuracy: 0.8357\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 214s 9ms/sample - loss: 0.2465 - accuracy: 0.9034 - val_loss: 0.4034 - val_accuracy: 0.8258\n"
     ]
    }
   ],
   "source": [
    "unicorns = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-45a753be58ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To speed up training, increase batch size. Can do *way* more epochs this way.\n",
    "Worth noting that the previous fit is saved within the compiler even if you interrupt kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(unicorns.history['loss'])\n",
    "plt.plot(unicorns.history['val_loss'])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. \n",
    "\n",
    "# LSTM Text generation with Keras (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_files = os.listdir('./articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 340: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b19e1ec3a88e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'txt'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./articles/{file}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\u4-s3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 340: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in data_files:\n",
    "    if file[-3:] == 'txt':\n",
    "        with open(f'./articles/{file}', 'r') as f:\n",
    "            data.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Focus on the shapes of the stuff we're working with to get a sense of what's going on (even if we don't have a mathematical intuition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "text = ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LambdaCallback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c22858002bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LambdaCallback' is not defined"
     ]
    }
   ],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to use a Keras LSTM to generate text on today's assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Review\n",
    "\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "    * Sequence Problems:\n",
    "        - Time Series (like Stock Prices, Weather, etc.)\n",
    "        - Text Classification\n",
    "        - Text Generation\n",
    "        - And many more! :D\n",
    "    * LSTMs are generally preferred over RNNs for most problems\n",
    "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
    "    * Keras has LSTMs/RNN layer types implemented nicely\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
    "    * Shape of input data is very important\n",
    "    * Can take a while to train\n",
    "    * You can use it to write movie scripts. :P "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S3 (Python3)",
   "language": "python",
   "name": "u4-s3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
